# 2 . Desenvolvendo sua Primeira API com FastAPI, Python e Docker
## Sumário 
- [Sobre a expert](#1-sobre-a-expert)
- [Apresentação do projeto](#2-apresentação-do-projeto-e-instruções)
- [Criação Atleta](#3-criação-de-schemas-e-models---entidade-atleta)
- [Criação Categoria e CT](#4-criação-de-schemas-e-models---entidades-categoria-e-centro-de-treinamento)
- [Docker e Alembic](#5-utilização-do-docker-compose-e-configuração-do-alembic)
- [Configurando o banco e Settings](#6-inserindo-configurações-do-banco-de-dados-e-adicionando-sttings)
- [Rota Categoria](#7-criação-das-rotas-de-categoria)
- [Rota Centro Treinamento](#8-criação-das-rotas-de-centro-de-treinamento)
- [Rota Atleta PT.1](#9-criação-das-rotas-de-atleta---pt1)
  - [Rota Atleta PT.2](#91-criação-das-rotas-de-atleta---pt2)
- [Consumindo API com Postman](#10-consumindo-api-com-postman)
- [Entendendo do Desafio](#11--entendendo-o-desafio)

---
## 1. Sobre a Expert
Esse módulo será focado em flashAPI, e as documentações necessárias estão presentes no GITHUB

---
## 2. Apresentação do projeto e instruções
---
## FastAPI
Framework FastAPI, alta performance, fácil de aprender, fácil de codar, pronto para produção. FastAPI é um moderno e rápido(alta performance) framework web para construção de PAIs com Python 3.6 ou superior, baseado nos type hints padrões do Python. 

### Async 
Código assíncrono apenas significa que a linguagem tem um jeito de dizer para o computador/programa que em um certo ponto, ele terá que esperar por algo para finalizar em outro lugar.    

### Projeto 
#### WorkoutAPI
Está é uma api de competição de crossfit chamada WorkoutAPI. é uma API pequena, devido a ser um projeto mais hands-on e simplificado nós desenvolveremos uma API de poucas tabelas, mas com o necessário para você aprender como utilizar o FastAPI.

#### Modelagem de entidade e relacionamento - MER

<table style="text-align: center; width: 100%;"> 
<tr>
    <td style="text-align: center;">
    <img src="imgs/MER_Workout.png" alt="MER" width="75%"/>
    </td>
</tr>
</table>

#### Stack da API
A API foi desenvolvida utilizando o fatapi(async), junto das seguintes libs: `alembic, SQLAlchemy, pydantic.` Para salvar os dados está sendo utilizado o `postegres`, por meio do `docker`


#### Execução da API
Para executar o projeto, utilizei a `pyenv`, com a versão 3.11.4 do python para o embiente virtual.
Caso opte por usar pyenv, após instalar, execute:

```bash
pyenv virtualenv 3.11.4 workoutapi
pyenv activate workoutapi
pip install -r requirements.txt
```
Para subir o banco de dados, caso não tenho o `docker` e o `docker-compose` instalado, faça a instalação logo em seguida execute:
```bash
make run-dcoker
```
para criar uma migration nova, execute:
```bash
make create-migrations d="nome_da_migration"
```
para criar o banco de dados, execute:
```bash
make run-migrations
```

#### API
Para subir a API, execute:
```bash
make run
```
acesse: https://127.0.0.1:8000/docs

#### Desafio final 

1. Adicionar query parameters nos endpoints 
  - Atleta 
    - nome 
    - cpf
2. Customizar response de retorno de endpoints
  - get all
    - Atleta
      - Nome
      - Centro de treinamento 
      - Categoria
3. Manipular exceção de integridade dos dados em cada módulo/tabela
  - sqlalchemy.exc.IntegrityError e devolver a seguinte mensagem: "Já existe um atleta cadastrado com o cpf: x"
  - status_code: 30 
4. Adicionar paginação utilizando a lib: fatapi-pagination
  -limit e offset

--- 
<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">Observação</strong>
  <p>O código a ser desenvolvido será feito em outro repositório.</br>
  <b>Neste documento conterá apenas informações sobre os código a informações 
  relevantes sobre o projeto.</b>
  </p>
</div>

## 3. Criação de schemas e models - Entidade Atleta
<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">Observação</strong>
   <p> Durante a execução desse curso não foi utilizado o `.venv` </br>
   padrão muitas vezes utilizado e sim o pyenv 
  </p>
</div>

Após a configuração do pyenv foi realizado a criação de um sub-diretório dentro do repositório, chamado de `workout_api`, com 2 arquivos iniciais.   
Sendo eles `__init__.py` e o arquivo `main`, dentro do main, foi realizado import da `FASTAPI`.  
Dentro do arquivo main, foi realizado as configurações básicas do servidor a ser criado com as libs `Fastapi &  uvicorn`. para tal processo foi realizado a seguinte sintaxe:  
```py
from fastapi import FastAPI

app = FastAPI(title="WorkoutAPI")

if __name__ == "main":
    import uvicorn

    uvicorn.run("main:app", host="0.0.0.0", port=8000, log_level="info", reload=True)

```
Sobre os comandos listados acima vale ressaltar alguns pontos, send o primeiro realizamos a instância de um objeto nomeado app com as propriedades da FastAPI e passado como parâmetro dentro dos possíveis apenas o title, para que esse tenha um titulo *"personalizado"*, após o processo acima, foi inicializado o main do arquivo importando a biblioteca `uvicorn` e realizado a instância do método run da biblioteca, para tal foi realizado a seguinte passagem de argumentos: 
1. Nome do main caracterizado pelo trecho `"main:app"`, ou seja realizando a atribuição do objeto app para main.
2. informações de ip e porta caracterizados pelos trechos: `host e port`, como o servidor será executado localmente não foi realizado a passagem de um ip e porta específico 
3. O parâmetro `log_level`, foi atribuído também nessa passagem esse parâmetro é responsável por realizar o log das operações no terminal. 
4. O parâmetro `realod`, foi habilitado também para que caso seja realizado alguma alteração dentro do código não seja necessário parar o servidor que está sendo criado, ou seja esse parâmetro irá reiniciar automaticamente o servidor criado e *"entender"*, quais alterações foram aplicadas.

Após a confecção do arquivo main, do projeto foi realizado a inicialização do mesmo através da sintaxe:
```bash
# Como o arquivo main, não se encontra na pasta raiz do projeto
# foi passado o nome da pasta antes do arquivo main:app
uvicorn workout_api.main:app --reload
```
Outro ponto passado também para facilitar o processo de "subir a API", foi realizado a criação de um `Makefile`, esse arquivo em grosso modo serve como um facilitador de alguns comandos, ou seja adicionamos alguns comandos dentro desse arquivo e a partir de então não será necessário realizar a digitação do comando por completo. Dentro desse arquivo foi adicionado o seguinte comando:
```makefile
run:
	@uvicorn workout_api.main:app --reload
```
Com esse arquivo diretamente na raiz do projeto, para que a API seja subida novamente basta digitar agora no terminal o seguinte comando abaixo:
```bash
make run
```
ou seja substituímos o comando `uvicorn workout_api.main:app --reload` por apenas `make run`

---
Notações:
Após a configuração inicial do projeto citada acima foi realizado a criação da primeira entidade do projeto que no caso foi o atleta. 

Para tal foi criado um diretório nomeado de `atleta` , dentro do sub-diretório workout_api, realizado a criação do arquivo `__init__.py`, e criado 2 outros arquivos sendo o models e schemas, onde dentro do arquivo de schemas, foi realizado a configuração da entidade atleta, para tal utilizamos a biblioteca `pydantic` com os módulos `BaseModel, Field, PositiveFloat`, bem como utilizamos também a `typing` 
a classe atleta foi por notação da `pydantic`, essa classe deverá entender/herdar a classe `BaseModel`. 
dentro da classe em questão foi realizado a criação dos atributos da classe conforme o mer com os atributos `nome,cpf,idade,peso,altura e sexo`, foi utilizado o `Annotated`, para atribuir algumas informações dessa entidade como o tipo do campo, e informações dentro do campo caracterizado pelo método `Field` passando os parâmetros de descrição exemplo e em alguns casos tamanho Máximo, outro ponto que é valido ressaltar e que a biblioteca da pydantic oferece para definição de campos do tipo **float** um método chamado de PositiveFloat, no qual define que esse atributo não aceitará valores negativos.

Após a criação do Schema do atleta criamos um model, e nesse ponto conforme passado, em aula devemos criar um classe *Abstrata* de modelo, para tal criamos um classe chamada de BaseModels que herda propriedades de `DeclarativeBase`, essa classe abstrata criada, tem como objetivo criar um UUID, e que esse atributo não seja exposto para o usuário que irá consumir a API.  
De posse dessa classe em contrib, criamos o nosso model para atleta, onde sim criaremos uma tabela de atleta, nea utilizamos as importações de 
```py 
sqlalchemy, datetime, BaseModel
# Sendo BaseModel nossa classe abstrata para o UUID
```
para esse arquivo importamos os módulos `Mapped, mapped_column` (que também foram utilizados na base model). 
Dentro da classe criamos a tabela atletas que seguiu o MER e o schema, porém para criação a sintaxe foi a seguinte 
```py
# Imporações da bibliotecas e módulos
class AtletaModel(BaseModel):
  __tablename__ = 'atletas' # aqui foi definido o nome da tabela
    pk_id: Mapped[int] = mapped_column(Integer, primary_key=True)
    nome: Mapped[str] = mapped_column(String(50), nullable=False)
```
No exemplo acima seguimos a notação da sqlalchemy, e um ponto interessante a ser notado é que como a classe de models de atleta está herdando a propriedade da BaseModel criada em contrib, não foi criado diretamente na tabela o UUID, pois esse não será informado ao usuário que irá consumir essa API. a notação para essa criação segue o padrão de 
1. Nome do campo (pk_id)
2. Mapped[int] define qual será o tipo do campo a ser criado. 
3. mapped_cloumn(Integer, primary_key=True) Nesse trecho definimos qual é o tipo condizente no banco para a coluna e suas propriedades. 
No exemplo do nome não foi passado o comando primary_key e sim nullable que informa que essa tabela não será nula. 

--- 
## 4. Criação de schemas e models - Entidades Categoria e Centro de treinamento
<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">Observação</strong>
   <p> Como o processo de inicialização do servidor via makefile. 
   Foi retirado do código main a parte de inicialização do uvicorn  </p>
</div>


Assim como fora criado para os models uma classe genérica para o schema de dados para as demais entidades do projeto, porém a classe em questão será configurada de forma abstrata seguindo os passo descritos abaixo:
1. Foi criado no diretório nomeado de `contrib` a classe BaseSchema sendo uma classe filha de BaseModel
2. Foi realizado o processo de abstração da classe, criando uma espécie de subclasse denominada de Config. 
3. Como a classe abstrata em questão descende de BaseModels, foi realizado o processo de instância do objeto `forbid` (Esse atributo em sí serve para determinar que o Schema a ser herdeiro dessa classe não aceite campos extras, que não estão no models), e posteriormente realizado a configuração de ()`from_attributes` como verdadeiro, esse método será repensável pela conversão de models para Schemas e vice versa .

Pós as correções aplicadas nas classes até o momento iremos dar inicio a confecção das demais entidades ( Centro de treinamento e categoria). 

Para a aplicação dessas entidades, assim como feito para entidade atleta também iremos realizar a confecção de um diretório com os arquivos `__init__.py, schemas.py e models.py`, para cada entidade necessária. 
A sintaxe de criação dos campos das demais entidades assemelha-se bastante com o que já foi visto anteriormente na [criação da entidade atleta](#3-criação-de-schemas-e-models---entidade-atleta), onde o único ponto que não foi passado anteriormente trata-se do processo de relacionamento entre as entidades. Para tal seguimos a seguinte sintaxe:
Dentro da classe `AtletaModel` da entidade Atleta em models, iremos adicionar 2 *(duas)* linhas em nosso código para referenciar a chave estrangeira da entidade `Categoria`, conforme exemplo:
```py
categoria: Mapped["CategoriaModel"] = relationship(back_populates="atleta")
categoria_id = Mapped[int] = mapped_column(ForeignKey("categorias.pk_id"))
```
1. categoria: Mapped["CategoriaModel"], esse trecho será responśavel por "apontar" que o campo categoria, faz referência a classe CategoriaModel, o que auxilia também na não realização de importação circular em nosso código. 
2. relationship(back_populates="atleta"), com esse trecho utilizamos o método `relationship` da biblioteca `sqlalchemy.orm`, e adicionamos como parâmetro em back_populates o valor atleta, que informa que o relacionametno será feito na tabela `atleta` que foi criada na casse atleta. 
3. categoria_id = Mapped[int] , nesse trecho o relacionamento por fim dentro da classe é realizado com o campo de fk, propriamente dito, nomeamos o campo com o nome do relacionamento e tipamos ele. 
4. mapped_column(ForeignKey("categorias.pk_id")), nesse trecho estamos utilizando do método `ForeignKey` da biblioteca `sqlalchemy`, onde passamos como argumento o nome da tabela a ser relacionada e qual será o campo de referência. 

Os passo acima foram aplicados dentro da classe `AtletaModel` da entidade atleta, porém temos que realizar a parte de relacionamento por assim se dizer no model correspondente, para isso dentro da classe `CategoriaModel` realizamos a adição do campo:
```py
atleta: Mapped["AtletaModel"] = relationship(back_populates="categoria")

```
onde indicamos que o atributo atleta referência a classe `AtletaModel` caracterizado pelo valor atribuido com a propriedade relationship, e diferente do que fora feito em atleta o valor do parâmetro `back_populates` está recebndo a tabela categoria , o mesmo será aplicado para entidade Centro de treinamento, onde os pontos a serem modificado ou acrescidos são :
1. Na entidade atleta será criado 2 camposd e relacionamento para centro de treinamento assim como feito para categorias, apontando a classe de centro de treinamento e sua chave primária. 
2. Na entidade centro_treinamento será criado um atributo atleta assim como feito em categoria porém passando para o relacionamento em back_populates, o nome da tabela da entidade que no caso foi nomeada de `centro_treinamentos`.
--- 
## 5. Utilização do Docker Compose e configuração do Alembic
Como o foco desse módulo do curso não é detalhar o modo de criação de um docker estritamente falando, foi construido um modelo *"genérico"* para tal, conforme a seguinte estrutura listada abaixo:
```yaml
version: '3'
services:
  db:
    image: postgres:11-alpine
    environment:
      POSTGRES_PASSWORD: workout
      POSTGRES_USER: workout
      POSTGRES_DB: workout
    ports:
      - "5432:5432"

```
No arquivo nomeado de `docker-compose.yaml` criado na raiz do projeto, utilizamos a configuração listada acima, para que a explicação não fique vaga irei explicar brevemente as linhas escritas no arquivo:
-  version, identifica qual será a versão utilizada pela imagem docker. 
-  services, identifica quais serão ou qual será o serviço a ser "instânciado" no container, no caso o serviço foi nomeado como db, onde nele inserimos alguns parâmetros:
  1. image: imagem que será utilziada para o serviço de banco de dados. 
  2. enviroment:  Define as váriaveis de ambiente da imagem em questão no contexto desse projeto as variaveis definidas, foram as básicas e padrões de uma imagem docker de postgres, senha usuário e banco de dados respectivamente. 
  3. ports: define o de para das portas que serão utilizadas na imagem docker, e a porta utilizada na máquina/servidor. foi utilziada a 5432 porta padrão do postgres

Pos build da imagem docker para o banco de dados, será utilizado a biblioteca do python `alembic`, assim como as bibliotecas anteriormente utilizadas, foi realizado a instalação da mesma através do comando:

```bash
pip install alembic
```
Com a biblioteca instalada no nosso ambiente, iniciaremos sua utilização ainda dentro do `bash` com o comando :
```bash
alembic init alembic
```
Com o comando acima, será criado no projeto a estrutura padrão do `alembic`, que é construido em um diretório de mesmo nome contendo, um sub-diretório de version, um arquivo python nomeado de env, um readme.md e um arquivo de extensão `py.mako` de scripts, e também é criado na raiz do projeto um aquivo `.ini`denomidado de alembic.

<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">Observação</strong>
   <p> Como padrão e boa prática de projetos em python, foi realizado a criação de um arquivo nomeado de 
   <b>requirements.txt</b>, para facilitar o processo de instalçao de bibliotecas utilizadas no projeto por outras pessoas ou máquina.</br>
   Para criar o arquivo em questão basta digitar no terminal :
   o comando :  pip freeze > requirements.txt
   </p>
</div>

Dentro do arquivo `alembic.ini` deverá ser editado algumas informações para o funcionamento correto do projeto em questão. 
1. `sqlalchemy.url = driver://user:pass@localhost/dbname` essa url deverá ser editada para que possa receber as informações de conexão com o banco de dados do projeto no nosso caso seguira as informações da sessão de **`environment`** do arquivo yaml, com um detalhe importante, como definido anteriormente o modelo da API em questão será assíncrona, então a url receberá como argumento, o modelo do banco de dados, `postgresql` + `asyncpg` quer irá definir que o driver de conexão a ser utilizado é o do postgresql no modo assíncrono. en sequencia, modificaremos as sessões _`user:pass@***\dbname`_ pelas informações de `environment` do docker.

<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">PS</strong>
   <p> Como foi definido no arquivo do alembic que o driver a ser utilizado, será o postgresql+<b>asyncpg</b>, o mesmo precisa ser instalado nas bibliotecas do projeto </p>
</div>

```bash
pip install asyncpg
# Atualiza o arquivo requirements com a nova biblioteca
pip freeze > requirements.txt
```
Dentro do enviroment `(env.py)` do diretório do alembic, realizaremos algumas alterações, pois o modelo criado por padrão está configurado para um modelo de conexão síncrona, o que não será utilizado nesse projeto. 
Uma das primeira edições do arquivo em questão será realizar o processo de importação das entidades criadas:
> Atletas, Centro de treinamento e Categorias
Para essa alteração dentro do arquivo adicionaremos a importação de nossa classe Basemodel com o comando:
```py 
from workout_api.contrib.models import BaseModel
# Em sequencia alteraremos no arquivo a linha de target_metadata, conforme abaixo
# Nesta linha estamos atribuindo que target_metadata tera as propriedades de BaseModel com a proriedade de metada
target_metadata = BaseModel.metadata
```
A primeira alteração realziada tem como objetivo criar uma especie de *"De/Para"*, informando que todas nossos arquivos Models, serão tabelas para nosso banco de dados. Para que esse processo obtenha sucesso devemos importar todos nossos módulos para esse arquivo, para facilitar esse processo podemos realizar os seguintes passsos:
1. Dentro do diretório `workout_api -> contrib`, iremos adicionar mais uma pasta chamada de __repository__, adicionaremos o inicializador `__init.py__` e um novo arquivo chamado de `models.py` dentro desse arquivo iremos realizar o import de todos os models anteriormente criados para entidades:  

```py
from workout_api.categorias.models import CategoriaModel
from workout_api.centro_treinamento.models import CentroTreinamentoModel
from workout_api.atleta.models import AtletaModel
```
com esse arquivo devidamente criado retornaremos ao nosso env do alembic, para importação das classes, esse processo é uma das maneiras que podem ser realizadas, e esse modelo fora o adotado durante do curso. Para a importação utilizamos:
```py
from workout_api.contrib.repository.models import *
```
Com os models devidamente importados daremos sequencia na modificação do arquivo.   

O próximo passo a ser executado será a criação de 2 métodos dentro do environment do alembic, e a modificação de outro conforme abaixo:
```py

def do_run_migrations(connection: Connection) -> None:
    context.configure(connection=connection, target_metadata=target_metadata)

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations():
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)


def run_migrations_online() -> None:
    asyncio.run(run_async_migrations())

```
Os métodos em questão são responsáveis por realiza a modificação do alembic para atuar de forma assíncrona, onde o primeiro método nomeado de `do_run_migrations` é reponsável por realizar a conexão com banco de dados, onde foi utilizado o objeto context e o método configure informado qual a conexão e o parâmetro target_metadata recebido será o anteriomente instânciado com nossa classe BaseModel

Em sequencia, foi criado uma função assíncrona __async def__  nomeada de `run_async_migrations` essa função recebe a conexão, conforme solicitado pela import que foi realizado de `from sqlalchemy.ext.asyncio import async_engine_from_config`, de posse desse objeto iniciamos a abertura de contexto de forma assíncrona desse objeto com o método connect() do mesmo, e informamos a função awit para realizar a conexão 
```py
#Abertura de contexto assíncrona
   async with connectable.connect() as connection:
    # iforma que a conexão e sincronização será realizada por outra função
        await connection.run_sync(do_run_migration)
```

por fim a modificação do método `run_migrations_online`, onde foi realizado o ultimo import da biblioteca `asyncio` e chamado o método `run`e passado como parâmetro a função de `run_async_migrations` 

Assim como foi realizado com o processo de comando do uvicorn, também foi utilziado comando no makefile, para facilitar o processo de criação e do banco conexão e migração. 
```makefile
create-migrations:
	@PYTHONPATH=$(PYTHONPATH):$(pwd) alembic revision --autogenerate -m "$(d)"

run-migrations:
	@PYTHONPATH=$(PYTHONPATH):$(pwd) alembic upgrade head
```
Os comandos acima realização o seguinte procedimento, o trecho de `@PYTHONPATH` define a variável  de ambiente, que diz ao interpretador Python onde procurar os modulos de importação e seus pacotes. 
O trecho de atribuição `$(PYTHONPATH):` essa sintaxe reatribui o valor anteriormente da variável de ambiente para receber, o comando seguinte os carácteres `:` são separadores padrões do bash linux, a *"macro "* `(pwd)` siginifica print working directory, e um comando shell para reotnrar o caminho completo do diretório autal, por fim ele realiza o comando do alembic de revisão com o argumento autogenerate -m  de comentário que é passado o argumento desse comentário em $(d)". 
já o comando do makefile para run-migrations realiza o a migração dos models para o banco.

--- 
## 6. Inserindo configurações do banco de dados e adicionando sttings
Dando inicio no processo de será criado na raiz do projeto um arquivo chamado `routers` esse arquivo será responsável por criar as rotas de conexão com os end-points da api.  

Na biblioteca da fastapi, existe uma importação que irá nos auxiliar com esse processo essa lib é a `APIRouter`.

Porém antes de realizar a configuração das rotas, devemos criar os arquivos de configuração para tal. para esse processo dentro do diretório da nossa API, criaremos um sub-diretório chamado de configs, e uma classe de configuração, e como já foi realizado anteriormente, esse processo será inicializado com a importação  de mais uma biblioteca do python. 

```bash
pip install pydantic-settings 
# Após a instalação do pacote, iremos adicionar no requirements
 pip freeze > requirements.txt 
```
Dentro do diretório recém criado, criaremos mais um arquivo chamado de `settings`, esse arquivo tem como objetivo de criar os tipos de configuração da API. Como o projeto está utilizando como base na FrameWork FastAPI, ele nos fornece uma serie de ferramentas, e uma delas que é valido de ser ressaltada é a possibilidade de criar suas próprias configurações, o que em comparação a framewok `Django`. de posse dessa configurações dentro da do arquivo de configuração (settigns), iremos criar um classe de configuração com base em uma classe da biblioteca recém instalada `pydantic-settings` especificamente 
a classe `BaseSettings`.   
No arquivo especificamente foi criado uma única configuração até o momento que foi nomeada de DB_URL, essa configuração receberá os valores da Url utilizada dentro do arquivo do alembic, e por fim atribuiremos a um objeto de mesmo nome da classe recebendo os valores da classe conforme exemplo abaixo:  
```py
from pydantic import Field
from pydantic_settings import BaseSettings


class Settings(BaseSettings):
    DB_URL: str = Field(
        default="postgresql+asyncpg://workout:workout@localhost/workout"
    )


settings = Settings()


```
Dando seguimento a configuração desta etapa precisamos de outras configurações, para o caso do correto funcionamento do método de post da api precisamos criar algumas dependências no projeto e uma delas é uma __`engine`__ para realizar a sessão com banco de dados. 
Ainda dentro do diretório de config, realizaremos a criação de um arquivo nomeado de `database.py. Dentro desse arquivo iremos importar __4__ bibliotecas diferentes, sendo essas listadas abaixo:
```py
from typing import AsyncGenerator
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
```
<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">IMPORTANTE</strong>
   <p> Como nossa API está sendo construida em um modelo de construção ASSÍNCRONA, as importações realizadas, 
   o modelo da engie será com base nesse modelo. 
   </p>
</div>

após a imotação das bibliotecas, criaremos a engine e para tal utilizaremos o arquivo anteriormente criado mais especificamente o objeto de settings, com a criação da engine, também se faz necessário realizar a criação de uma sessão com o banco de dados, posteriormente criaremos mais uma função __assíncrona__ que foi nomeada de `get_session`, cuja a qual iremos forçar o seu retorno como `AsyncGeneratior`, essa função retornar um gerador de sessão, com essa configurações nosso arquivo de database ficara da seguinte maneira. 

```py
from workout_api.configs.settings import settings

engine = create_async_engine(settings.DB_URL, echo=False)
async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)


async def get_session() -> AsyncGenerator:
    async with async_session() as session:
        yield session
``` 
Pós toda a configuração feita, iremos criar 2 arquivos a priore sendo uma mais _"genérica"_ que será criada dentro do nosso sub-diretório __`workout_api`__, esse arquivo mais genérico será chamado de routes, e esse arquivo será o responsável por criar propriamente dito as rotas de nossa api, esse arquivo fará a inclusão das rotas de cada entidade criada em nosso projeto, no modelo descrito abaixo, contamos com a importação da biblioteca APIRouter da framework fastapi, e também conforme mostrado abaixo,  iremos importar um outro ponto muito importante que será nossa controlador para entidade. pós importação é dado o inicio da instância de um objeto que foi nomeado de api_router que recebeu como propriedade a biblioteca APIRouter, com o objeto instanciado, iremos utilizar o método `include_router`, esse objeto receberá como parâmetros a classe de controle mencionada, um prefixo e sua tag. 
```py
from fastapi import APIRouter
from workout_api.atleta.controller import router as atleta

api_router = APIRouter()

api_router.include_router(atleta, prefix="/atletas", tags=["atletas/"])
```
Como visto acima, esse objeto precisa de um controller que no caso exemplificado advém da nossa entidade atleta, então para tal criaremos um arquivo chamado de `controller.py`, esse arquivo será criado diretamente no subdiretório que contém os arquivos da entidade __atleta__, e para tal também importaremos o APIRouter, e iremos instanciar um objeto que será nomeado de router para melhor identificação na importação que foi feita no nosso arquivo routers,com a utilização de um decorador no nosso objeto utilizamos o método post, e passamos o como parâmetro a URL relativa na função decorada por fim criamos uma função assíncrona para o processo, deixando nosso código da seguinte maneira. 
```py
from fastapi import APIRouter

router = APIRouter()


@router.post(path="/")
async def post():
    pass
```
Em sequência iremos editar nosso arquivo main para que ele possa exibir essa rota criada, para tal importamos essa rota criada, e utilizamos o método `incluide_router` que nesse arquivo recebera essa importação. Com essa configuração será apresentado no /docs da nossa api esse endpoint, porém podemos incrementar esse __"endpoint"__ com alguns parâmetros, sendo eles : 

1. `summary="Criar um novo atleta",` Esse primeiro parâmetro irá adicionar a nosso endpoint, uma descrição do intuido daquele endpoint
2. `status_code=status.HTTP_201_CREATED` Já esse parâmetro tem como objetivo uma atender a uma convenção se podemos assim nomear, sobre o status da aplicação ele informa que a criação foi correta. 

Agora com o decorador da função post parametrizado de maneira aprimorada, iremos definir para nossa função post, a sua funcionalidade, como estamos criando um método post, presupõe-se que ele irá se conectar ao banco de dados da api, e fará um _"insert_ no banco de dados, então para tal dentro do método `post` que foi criado no controller, passaremos como parâmetro da função a sessão do banco, e para estabelecer essa sessão é necessário um meio de obter tal, o que poderia será o get_session anteriormente criado, porém não realizaremos essa importação da nossa engine, e sim faremos ele como uma dependência.  
Para criar essa dependência iremos criar um arquivo dentro do subdiretório contrib chamado de `dependencies.py `, esse arquivo servirá como abstração desse processo e será utilizado de forma geral permitindo a reutilização do mesmo de uma forma geral. 
```py
from typing import Annotated
from fastapi import Depends
from sqlalchemy.ext.asyncio import AsyncSession

from workout_api.configs.database import get_session


DatabaseDependency = Annotated[AsyncSession, Depends(get_session)]
```

Nesse arquivo utilizamos 4 importações, 3 importações de pacotes já vistos aqui atenteriormente, e 1 própria no caso o método get_session criado no config, esse objeto recebe o método Annotated da biblioteca python, e como seu parâmetros o método do AsyncSessiom do sqlalchemy, e um novo método que é o `Depends` esse método está recebendo como parâmetro nosso get_session, e esse método `Depends` é responsável por informar qual é a dependência desse controller, que no casso será o get session. Apenas para frisar para o Annotated primeiro informamos qual é sua tipagem assíncrono ou síncrono para esse caso, e em sequencia informamos qual será o retorno que no caso é a dependência da sessão.  

Retornando ao nosso método post iremos então configurar nossa sessão com arquivo criado. tipando o primeiro parâmetro com esse objeto de database do contrib, depois informaremos mais um parâmetro o tipando com a classe de atleta do schema, para que possamos melhor disitinguir renomearemos essa classe criada para `AtletaIn`, outra coisa a ser feita é criar dentro desse arquivo do schema mais uma classe que nomearemos como `AtletaOut`, pois quando realizarmos a inserção no banco de dados, essa não deverá ter por exemplo a data de criação, que é um atributo presente no banco de dados, porém esse atributo quando for devolvido ou quando ele sair esse atributo em sí é retornado, e quem cria a data de criação será o código e não o usuário, o mesmo é valido pelo UUID, então para tal alteraremos nosso schema de contrib também criando uma classe chamada de OutMixin, essa classe também herdará propriedades de BaseModel, e erá terá 2 atributos que serão tipados com UUID4 da pydantic e o created_at que será tipado com DateTime. É necessário que esse atributos fiquem na classe Out pois o usuário não deve ter controle nem do ID interno tão pouco da data de criação, esses valores serão atribuidos no quando o post for feito. Deixando então essa classe de schema de contrib da seguinte maneira

<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">IMPORTANTE</strong>
   <p> Para não "Quebrar" nosso código criamos uma nova classe com nome de atletaIn que herdará 
   as da classe atleta anteriormente criada, que será como uma classe base por assim dizer.
   </p>
</div>
 
 Deixando nosso método de post da seguinte maneira até o momento. 
```py
@router.post(
    path="/", summary="Criar um novo atleta", status_code=status.HTTP_201_CREATED
)
async def post(db_session: DatabaseDependency, atleta_in: AtletaIn = Body(...)):
    pass

```
Até o momento nosso controller está configurado com o decorador do método post da fat api, 
e nosso método post com 2 parâmetros sendo eles db_session estando tipado com o nosso recém criado DatabaseDependency, e o outro parâmetro atleta_in estando tipado com nossa recém adicionada classe de atletaIn do schema da entidade atleta.

---
## 7. Criação das rotas de Categoria
Dando continuidade a criação da nossa API, e por motivos mais lógicos daremos sequência ao projeto criando os outros EndPoints, no casso abaixo será criado o endpoint de categoria primeiramente, pois como a entidade atleta tem relacionamento direto com as duas outras entidades, fará mais sentido criar esses endpoint primeiro, para ai sim criar o endpoint de atleta. Dado o disclaimer vamos configurar nosso endpoint de atleta. 

<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">IMPORTANTE</strong>
   <p> Assim como foi realizado em atleta as configurações de class out para schama, e adição do endpoint 
   no router também foi realizada, com a diferença que para a classe out de categoria não foi realizado a criação de um atributo datetime
   já que esse não existe na tabela.
   </p>
</div>

A criação do nosso método de post de categoria seguirá o mesmo padrão visto até aqui de atleta mas com algumas renomeações de parâmetros/atributos conforme descrito abaixo:
```py 
from uuid import uuid4
from fastapi import APIRouter, Body, status

from workout_api.categorias.schemas import CategoriaIn, CategoriaOut
from workout_api.contrib.dependencies import DatabaseDependency

router = APIRouter()


@router.post(
    path="/",
    summary="Criar uma nova Categoria",
    status_code=status.HTTP_201_CREATED,
    response_model=CategoriaOut,
)
async def post(
    db_session: DatabaseDependency, categoria_in: CategoriaIn = Body(...)
) -> CategoriaOut:
    categoria_out = CategoriaOut(id=uuid4(), **categoria_in.model_dump())
    breakpoint()
    pass

```
A diferença desse método para o antes criado se da em alguns pontos para além da renomeação de parâmetros.
1. Foi realizado a tipagem do retorno desse método sendo que ele será do tipo `CategoriaOut` (Classe criada em schema da entidade categoria)
2. realizamos a instância de um objeto nomeado de categoria_out que recebe essa classe, e como mencionado anteriormente essa entidade irá fazer o processo de criação de unique ID ou id serial, então para tal passamos como parâmetro id recebendo a função uuid4 da biblioteca uuid. 
3. Por fim estamos realizando o parse desse método para `categoria_in` utilizando conforme nova recomendação da pydantic utilização do método model_dump. 
Esse tipo de atribuição `"(**categoria_in.model_dump())"`  faz o processo de pegar o parâmetro informado na função post de `categoria_in: CategoriaIn = Body(...)` que tem como retorno um schema, e atribui os valores para outro schema.  
Para fins didaticos, adicionamos um breakpoint após a instância de categoria, para visualizarmos o retorno que está sendo obtido quando utilizamos esse endpoint na nossa api
```bash
categoria_out
CategoriaOut(nome='Scale', id=UUID('5a496cef-b610-4847-885c-36b3391e8745'))
(Pdb) categoria_in
CategoriaIn(nome='Scale')
(Pdb) categoria_in.model_dump()
{'nome': 'Scale'}
(Pdb) 
```
Pós realizar o post na api podemos utilizar no nosso terminal a digitação dos objetos para visualizarmos o retorno. e isso nos mostra o seguinte. 
1. Ao passar o objeto categoria_out nos é retornado o que seria inserido quais são os valores que estão sendo criados.
2. Ao informar categoria in será retornado apenas o que será exibido ou seja o nome da categoria
3. Porém ao realizar a passagem de `categoria_in.model_dump()` é retornado o mesmo valor de categoria porém como um dicionário de dados.
<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">IMPORTANTE</strong>
   <p> Durante a construção das classe de models, tivemos um problema de importação circular no projeto. 
   Para correção desse problema realizaremos a edição do arquivo init base do subdiretório realizando nele essas importações.
   </p>
   <p>
   from workout_api.atleta.models import AtletaModel </br>
   from workout_api.categorias.models import CategoriaModel </br>
   from workout_api.centro_treinamento.models import CentroTreinamentoModel </br>
  </p>
</div>

Com a importação realizado nosso model de categoria ficou da seguinte forma:

```py 
from uuid import uuid4
from fastapi import APIRouter, Body, status

from workout_api.categorias.models import CategoriaModel
from workout_api.categorias.schemas import CategoriaIn, CategoriaOut
from workout_api.contrib.dependencies import DatabaseDependency

router = APIRouter()


@router.post(
    path="/",
    summary="Criar uma nova Categoria",
    status_code=status.HTTP_201_CREATED,
    response_model=CategoriaOut,
)
async def post(
    db_session: DatabaseDependency, categoria_in: CategoriaIn = Body(...)
) -> CategoriaOut:

    categoria_out = CategoriaOut(id=uuid4(), **categoria_in.model_dump())
    categoria_model = CategoriaModel(**categoria_out.model_dump())

    db_session.add(categoria_model)
    await db_session.commit()

    return categoria_out

```

Nesse modelo definimos a instancia de categoria_out e o parseamos como o schema de categoria in, instanciamos categoria_model como objeto da classe de CategoriaModel com parse de sua atribuição sendo com o valor obtido em categoria_out. e por fim adicionamos nossa sessão recebendo o objeto categoria_model. Como essa api é do tipo assíncrona, nosso commit deve ser definido como await. e definimos nosso retorno como a instância de categoria_out.



---
## 8. Criação das rotas de Centro de treinamento
---
## 9. Criação das rotas de Atleta - PT1
---
## 9.1. Criação das rotas de Atleta - PT2
---
## 10. Consumindo API com Postman
---
## 11.  Entendendo o Desafio
---
### Links Uteis
- [FastAPI](https://fastapi.tiangolo.com)
- [Pydantic](https://docs.pytantic.dev/latest/)
- [SQLAlchemy](https://docs.sqlalchemy.org/en/20)
- [Alembic](https://alembic.sqlalchemy.org/en/latest/)
---
As respostas da aula 2 estão [aqui](IMGS)

tabela exemplo 
| | |
| -- | -- |
| nome | valor |

<div style="border-left: 4px solid red; background-color:rgb(22, 23, 24); padding: 10px;">
  <strong style="color: red;">Exemplo de alerta</strong>
  <p> Somente um exemplo.</p>
</div>

exemplo código 
```
print("Hello World!")
```
---
<table style="text-align: center; width: 100%;"> 
<caption><b>Skils do projeto </b></caption>
<tr>
    <td style="text-align: center;">
    <img alt="Markdown" src="https://img.shields.io/badge/markdown-%23000000.svg?style=for-the-badge&logo=markdown&logoColor=white"/>
    </td>
    <td style="text-align: center;">
    <img alt="Python" src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54"/>
    </td>
    <td style="text-align: center;">
    <img alt="VSCode" src="https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white"/>
    </td>
<tr> 
</table>

---
Titulo: 2 . Desenvolvendo sua Primeira API com FastAPI, Python e Docker 

Autor: Thierry Lucas chaves

Data criacao: 21/08/2025

Data modificacao: 21/08/2025

Versao: 1.0  

---